{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17df5212caf73cc2cb9bed3c4f699c50c0f2482c"
   },
   "source": [
    "# Costa Rican Household Poverty Level Prediction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Objective \n",
    "The objective of the Costa Rican Household Poverty Level is to develop a machine learning model that can predict the poverty level of households using both individual and household characteristics. \n",
    "\n",
    "### Problem Statement \n",
    "The data obtained for this problem is in two files: train.csv and test.csv. The training set has 9557 rows and 143 columns, while the testing set had 23856 row and 142 columns. Each row represents one individual and each column is a feature, which is either unique to an individual or for the whole household of the individual. The extra column in the training set is 'Target' which represents the poverty level on a 1 - 4 scale and is the label for the competition. \n",
    "\n",
    "The target values are\n",
    "1. 1 = extreme poverty\n",
    "2. 2 = moderate poverty\n",
    "3. 3 = vulnerable households\n",
    "4. 4 = non volunerable households\n",
    "\n",
    "The problems that need attention are \n",
    "1. As the objective here is to predict the poverty on a household level, an extensive EDA is required on all features given about the household. We have to make a prediction for every individual in the test set, but only the heads of household are used in scoring which means heads of household is the factor to predict the poverty of the household. \n",
    "2. The raw data contains mix of both household and for each individual, grouping or aggregation of this data will be tricky.\n",
    "3. Some of the individuals belong to a house with no head of household which means that unfortunately we can't use this data for training. \n",
    "\n",
    "When the data, objective and problem statement are analyzed, it can be said that this is a classic example of a **Supervised Multi-Class classification Machine Learning Problem**. This is because, the data is provided with labels and the labels are discrete values with four classes. \n",
    "\n",
    "### Metrics Metrics used to evaluate is Macro F1 Score. \n",
    "Standard F1 score for binary classifcation problem is the harmonic mean of precision and recall. \n",
    "\n",
    "$$F_1 = \\frac{2}{\\tfrac{1}{\\mathrm{recall}} + \\tfrac{1}{\\mathrm{precision}}} = 2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}}$$\n",
    "\n",
    "For multi-class problems, we have to average the F1 score for each class. The macro F1 score averages the F1 score for each class_without taking account label imbalances_.\n",
    "\n",
    "$$\\text{Macro F1} = \\frac{\\text{F1 Class 1} + \\text{F1 Class 2} + \\text{F1 Class 3} + \\text{F1 Class 4}}{4}$$\n",
    "\n",
    "In other words, the number of occurrences of each label does not figure into the calculation when using macro (while it does when using the \"weighted\" score). (For more information on the differences, look at the [Scikit-Learn Documention for F1 Score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) or this [Stack Exchange question and answers](https://datascience.stackexchange.com/q/15989/42908). If we want to assess our performance, we can use the code:\n",
    "\n",
    "```\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_predicted, average = 'macro`)\n",
    "```\n",
    "\n",
    "### Roadmap\n",
    "\n",
    "1. Understand the problem\n",
    "2. EDA\n",
    "3. Feature Selection and Feature Engineering\n",
    "4. Compare baseline machine learning models\n",
    "    1. Try more complex models\n",
    "5. Optimize the selected model\n",
    "6. Investigate model prediction \n",
    "7. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File C:\\Users\u0007hpasupala1\\Documents\\GitHub\\Costa_Rican_Household_Poverty_Level_Prediction\\data\train.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bde38863efc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# read train data as train_data and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# test data as test_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\Users\\ahpasupala1\\Documents\\GitHub\\Costa_Rican_Household_Poverty_Level_Prediction\\data\\train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\Users\\ahpasupala1\\Documents\\GitHub\\Costa_Rican_Household_Poverty_Level_Prediction\\data\\test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ahpasupala1\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ahpasupala1\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ahpasupala1\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ahpasupala1\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ahpasupala1\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File C:\\Users\u0007hpasupala1\\Documents\\GitHub\\Costa_Rican_Household_Poverty_Level_Prediction\\data\train.csv does not exist"
     ]
    }
   ],
   "source": [
    "# Data Manipulation Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read train data as train_data and \n",
    "# test data as test_data\n",
    "train_data = pd.read_csv(\"C:\\Users\\ahpasupala1\\Documents\\GitHub\\Costa_Rican_Household_Poverty_Level_Prediction\\data\\train.csv\")\n",
    "test_data = pd.read_csv(\"C:\\Users\\ahpasupala1\\Documents\\GitHub\\Costa_Rican_Household_Poverty_Level_Prediction\\data\\test.csv\")\n",
    "\n",
    "# Check the dimensions of the table\n",
    "print(\"The dimension of the train table is: \", train_data.shape)\n",
    "print(\"The dimension of the test table is: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c03fcf5bf5689dede9120334323a0815bf41f526"
   },
   "source": [
    "The dimension of the table is (891, 12) which means there are 9557 rows and 143 columns in the train table and 23856 rows and 142 columns in the test table. Lets take a look at the first 5 rows of our train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9961b2af4409834f972852f38d84d5ae0014e3f2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "318a58ed24f020736d3bf5a896fd2359c0c531c2"
   },
   "source": [
    "Looking at the first five rows of the data , we can see that there are 130 integer columns, 8 float columns and 5 object columns. The integer columns probably represent Boolean variables i.e., 0 or 1 or ordinal variables with discrete ordered values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7f2df65201bbb4a34226fa339e18e3134110f58"
   },
   "source": [
    "\n",
    "Histograms for the numerical variables\n",
    "Histograms are very good visualization technique to check the distribution of numerical data. In our data set, target is an ordinal variable which indicates groups of income levels\n",
    "1. 1 = extreme poverty\n",
    "1. 2 = modern poverty\n",
    "1. 3 = vulnerable poverty\n",
    "1. 4 = non vulnerable poverty\n",
    "\n",
    "First let us explore the target variable and when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09c98fa2f6b0d99b2f40437698b1d81cf692734b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random \n",
    "import warnings\n",
    "import operator\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5aa5955f94ef80bc74a55c6ba1d4192f4c40a51b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_levels = train_data.loc[(train_data['Target'].notnull()) & (train_data['parentesco1'] == 1), ['Target', 'idhogar']]\n",
    "label_counts = train_levels['Target'].value_counts().sort_index().to_frame()\n",
    "target = label_counts\n",
    "levels = [\"Extreme Poverty\", \"Moderate Poverty\", \"Vulnerable\", \"Non Vulnerable\"]\n",
    "trace = go.Bar(y=target.Target, x=levels, marker=dict(color=['#FF0000', '#FFA500', '#0000FF', '#008000'], opacity=0.6))\n",
    "layout = dict(title=\"Household Poverty Levels\", margin=dict(l=200), width=800, height=400)\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3649d3bdf127c7b5cb0ea677c7bac74973973b8a"
   },
   "source": [
    "imbalanced class problem\n",
    "weighted F1 - Read and get notes\n",
    "\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43215d8cb6a1f67e5526023d6b18e30113a0e00b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.select_dtypes('object').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ab86afc0a18e68141c099d3058ff23ed7026b9f"
   },
   "source": [
    "id and idhogar - id variable. Make sense\n",
    "\n",
    "as per documentation\n",
    "1. dependency - Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n",
    "2. edjefe - Years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "3. edjefa - Years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f1369a4974f29c28293b8b6102fb0eb566ded43",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mapping = {\"yes\": 1, \"no\": 0}\n",
    "\n",
    "# Apply same operation to both train and test\n",
    "for df in [train_data, test_data]:\n",
    "    # Fill in the values with the correct mapping\n",
    "    df['dependency'] = df['dependency'].replace(mapping).astype(np.float64)\n",
    "    df['edjefa'] = df['edjefa'].replace(mapping).astype(np.float64)\n",
    "    df['edjefe'] = df['edjefe'].replace(mapping).astype(np.float64)\n",
    "\n",
    "train_data[['dependency', 'edjefa', 'edjefe']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd499ccc3ca7851a4dc65ca78e841cea53ce9b43",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.select_dtypes('float').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b983dde1e3ce9a5a629a98479341c72b61f38e3",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# Color mapping\n",
    "colors = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})\n",
    "poverty_mapping = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})\n",
    "plt.figure(figsize = (30, 16))\n",
    "\n",
    "# Iterate through the float columns\n",
    "for i, col in enumerate(train_data.select_dtypes('float')):\n",
    "    ax = plt.subplot(6, 2, i + 1)\n",
    "    # Iterate through the poverty levels\n",
    "    for poverty_level, color in colors.items():\n",
    "        # Plot each poverty level as a separate line\n",
    "        sns.kdeplot(train_data.loc[train_data['Target'] == poverty_level, col].dropna(), \n",
    "                    ax = ax, color = color, label = poverty_mapping[poverty_level])\n",
    "        \n",
    "    plt.title(f'{col.capitalize()} Distribution'); \n",
    "    plt.xlabel(f'{col}'); plt.ylabel('Density')\n",
    "\n",
    "plt.subplots_adjust(top = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf9465293b784f1efa65ea8f91f9bba136c6f6d5"
   },
   "source": [
    "1. v2a1 - Monthly rent payment\n",
    "2. v18q1 - number of tablets household owns\n",
    "3. rez_esc - Years behind in school\n",
    "4. dependency - Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n",
    "5. edjefe - years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "6. edjefa - years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "7. meaneduc - average years of education for adults (18+)\n",
    "8. overcrowding - No of persons per room\n",
    "9. SQBovercrowding - overcrowding squared\n",
    "10. SQBdependency - dependency squared\n",
    "11. SQBmeaned - square of the mean years of education of adults (>=18) in the household\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "204e35851bdfb022856be1d07e233c174af10570",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "labels = []\n",
    "values = []\n",
    "for col in train_data.columns:\n",
    "    if col not in [\"Id\", \"Target\"]:\n",
    "        labels.append(col)\n",
    "        values.append(spearmanr(train_data[col].values, train_data[\"Target\"].values)[0])\n",
    "corr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\n",
    "corr_df = corr_df.sort_values(by='corr_values')\n",
    " \n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(train_data[corr_df.col_labels[:10]].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8a6b1fb3cfc439aecbde746fd3b81d47586d27e"
   },
   "source": [
    "Errors in Labelling \n",
    "human entry errors, measurement errors, or sometimes just extreme values that are correct but stand out. For this problem, some of the labels are not correct because individuals in the same household have a different poverty level. We're not told why this may be the case, but we are told to use the head of household as the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0302036ee15476e0ea137d0829d0d527df3be0b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Groupby the household and figure out the number of unique values\n",
    "all_equal = train_data.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n",
    "\n",
    "# Households where targets are not all equal\n",
    "not_equal = all_equal[all_equal != True]\n",
    "print('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53b7ccc87543f3a2ea1060587400de9706749d22",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[train_data['idhogar'] == not_equal.index[0]][['idhogar', 'parentesco1', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "386e017a010f9c891f8c325b0a65e0f328debbb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "households_leader = train_data.groupby('idhogar')['parentesco1'].sum()\n",
    "\n",
    "# Find households without a head\n",
    "households_no_head = train_data.loc[train_data['idhogar'].isin(households_leader[households_leader == 0].index), :]\n",
    "\n",
    "print('There are {} households without a head.'.format(households_no_head['idhogar'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8402a8aac58871388b7acb902cb42ae7afac93c2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find households without a head and where labels are different\n",
    "households_no_head_equal = households_no_head.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n",
    "print('{} Households with no head have different labels.'.format(sum(households_no_head_equal == False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bab6776e54f0cd79d057d0c904cc51b070c061bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through each household\n",
    "for household in not_equal.index:\n",
    "    # Find the correct label (for the head of household)\n",
    "    true_target = int(train_data[(train_data['idhogar'] == household) & (train_data['parentesco1'] == 1.0)]['Target'])\n",
    "    \n",
    "    # Set the correct label for all members in the household\n",
    "    train_data.loc[train_data['idhogar'] == household, 'Target'] = true_target\n",
    "    \n",
    "    \n",
    "# Groupby the household and figure out the number of unique values\n",
    "all_equal = train_data.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n",
    "\n",
    "# Households where targets are not all equal\n",
    "not_equal = all_equal[all_equal != True]\n",
    "print('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5be3adf77d91c8a662ec6bb485e3bdd196bcc24c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add null Target column to test\n",
    "test_data['Target'] = np.nan\n",
    "add_data = train_data.append(test_data, ignore_index = True)\n",
    "\n",
    "# Number of missing in each column\n",
    "missing = pd.DataFrame(add_data.isnull().sum()).rename(columns = {0: 'total'})\n",
    "\n",
    "# Create a percentage missing\n",
    "missing['percent'] = missing['total'] / len(add_data)\n",
    "\n",
    "missing.sort_values('percent', ascending = False).head(10).drop('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b681a667fb0f2f41506a9e363ee71e1fddbeb6e8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_plot(col, title):\n",
    "    tr1 = train_data[train_data['Target'] == 1][col].value_counts().to_dict()\n",
    "    tr2 = train_data[train_data['Target'] == 2][col].value_counts().to_dict()\n",
    "    tr3 = train_data[train_data['Target'] == 3][col].value_counts().to_dict()\n",
    "    tr4 = train_data[train_data['Target'] == 4][col].value_counts().to_dict()\n",
    "    \n",
    "    xx = ['Extereme', 'Moderate', 'Vulnerable', 'NonVulnerable']\n",
    "    trace1 = go.Bar(y=[tr1[0], tr2[0], tr3[0], tr4[0]], name=\"Not Present\", x=xx, marker=dict(color=\"orange\", opacity=0.6))\n",
    "    trace2 = go.Bar(y=[tr1[1], tr2[1], tr3[1], tr4[1]], name=\"Present\", x=xx, marker=dict(color=\"purple\", opacity=0.6))\n",
    "    \n",
    "    return trace1, trace2 \n",
    "    \n",
    "tr1, tr2 = compare_plot(\"v18q\", \"Tablet\")\n",
    "tr3, tr4 = compare_plot(\"refrig\", \"Refrigerator\")\n",
    "tr5, tr6 = compare_plot(\"computer\", \"Computer\")\n",
    "tr7, tr8 = compare_plot(\"television\", \"Television\")\n",
    "tr9, tr10 = compare_plot(\"mobilephone\", \"MobilePhone\")\n",
    "titles = [\"Tablet\", \"Refrigerator\", \"Computer\", \"Television\", \"MobilePhone\"]\n",
    "\n",
    "fig = tools.make_subplots(rows=3, cols=2, print_grid=False, subplot_titles=titles)\n",
    "fig.append_trace(tr1, 1, 1)\n",
    "fig.append_trace(tr2, 1, 1)\n",
    "fig.append_trace(tr3, 1, 2)\n",
    "fig.append_trace(tr4, 1, 2)\n",
    "fig.append_trace(tr5, 2, 1)\n",
    "fig.append_trace(tr6, 2, 1)\n",
    "fig.append_trace(tr7, 2, 2)\n",
    "fig.append_trace(tr8, 2, 2)\n",
    "fig.append_trace(tr9, 3, 1)\n",
    "fig.append_trace(tr10, 3, 1)\n",
    "\n",
    "fig['layout'].update(height=1000, title=\"What do Households Own\", barmode=\"stack\", showlegend=False)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "653929e44af042d3dc321e2ac2d601c5f9d1dcc3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heads = train_data.loc[add_data['parentesco1'] == 1].copy()\n",
    "target = heads['v18q1'].value_counts().to_frame()\n",
    "levels = [\"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\", \"6.0\"]\n",
    "trace = go.Bar(y=target['v18q1'], x=levels, marker=dict(color='orange', opacity=0.6))\n",
    "layout = dict(title=\"v18q1 Value Counts\", margin=dict(l=200), width=800, height=400)\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "126ef85ad5ed676a221160588c106f2efb1be967",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heads.groupby('v18q')['v18q1'].apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75987e96d668f8708728645cef4265ef283be818",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_data['v18q1'] = add_data['v18q1'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4f3390caab23cb5756553c260b599686aac7f5b"
   },
   "source": [
    "v2a1: Monthly rent payment\n",
    "tipovivi1, =1 own and fully paid house\n",
    "tipovivi2, \"=1 own,  paying in installments\"\n",
    "tipovivi3, =1 rented\n",
    "tipovivi4, =1 precarious\n",
    "tipovivi5, \"=1 other(assigned,  borrowed)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02606cbbe1bf922a2a9dcc20257601ddda3de3fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_dists(col, title):\n",
    "    trace1 = go.Histogram(name=\"Extereme\", x=add_data[add_data['Target']==1][col])\n",
    "    trace2 = go.Histogram(name=\"Moderate\", x=add_data[add_data['Target']==2][col])\n",
    "    trace3 = go.Histogram(name=\"Vulnerable\", x=add_data[add_data['Target']==3][col])\n",
    "    trace4 = go.Histogram(name=\"NonVulnerable\", x=add_data[add_data['Target']==4][col])\n",
    "\n",
    "    fig = tools.make_subplots(rows=2, cols=2, print_grid=False)\n",
    "    fig.append_trace(trace1, 1, 1)\n",
    "    fig.append_trace(trace2, 1, 2)\n",
    "    fig.append_trace(trace3, 2, 1)\n",
    "    fig.append_trace(trace4, 2, 2)\n",
    "\n",
    "    fig['layout'].update(height=400, showlegend=False, title=title)\n",
    "    iplot(fig)\n",
    "\n",
    "compare_dists('v2a1', \"Monthy Rent for four groups of houses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75c44ebde7b8ae18712ed1dd4212bb83460de141",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "own_variables = [x for x in add_data if x.startswith('tipo')]\n",
    "target = add_data.loc[add_data['v2a1'].isnull(), own_variables].sum().to_frame()\n",
    "levels = [\"Owns and Paid Off\", \"Owns and Paying\", \"Rented\", \"Precarious\", \"Other\"]\n",
    "trace = go.Bar(y=target[0], x=levels, marker=dict(color='orange', opacity=0.6))\n",
    "layout = dict(title=\"Home Ownership Status for Household Missing Rent Payments\", margin=dict(l=200), width=800, height=400)\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "# tipovivi1, =1 own and fully paid house\n",
    "# tipovivi2, \"=1 own,  paying in installments\"\n",
    "# tipovivi3, =1 rented\n",
    "# tipovivi4, =1 precarious\n",
    "# tipovivi5, \"=1 other(assigned,  borrowed)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5df89e143a138fbe2fe26a4e51a6baa3ad3b228f"
   },
   "source": [
    "For the houses that are owned and have a missing monthly rent payment, we can set the value of the rent payment to zero. For the other homes, we can leave the missing values to be imputed but we'll add a flag (Boolean) column indicating that these households had missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd43d63ad43a08e7cad282dcaad79b30935fff3f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in households that own the house with 0 rent payment\n",
    "add_data.loc[(add_data['tipovivi1'] == 1), 'v2a1'] = 0\n",
    "\n",
    "# Create missing rent payment column\n",
    "add_data['v2a1-missing'] = add_data['v2a1'].isnull()\n",
    "\n",
    "add_data['v2a1-missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f7ba06a4a49c0a5d1161fa6fc002f7b1d30a28f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This variable is only collected for people between 7 and 19 years of age \n",
    "# and it is the difference between the years of education a person should have \n",
    "# and the years of education he/she has. it is capped at 5.\n",
    "print(add_data['rez_esc'].isnull().value_counts())\n",
    "\n",
    "add_data.loc[add_data['rez_esc'].notnull()]['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "579159d9dc536dd6f3cefa0a659498ff23af6dd3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_prominent(row, mats):\n",
    "    for c in mats:\n",
    "        if row[c] == 1:\n",
    "            return c\n",
    "    return \n",
    "\n",
    "def combine2(starter, colname, title, replacemap, plotme = True):\n",
    "    mats = [c for c in add_data.columns if c.startswith(starter)]\n",
    "    add_data[colname] = add_data.apply(lambda row : find_prominent(row, mats), axis=1)\n",
    "    add_data[colname] = add_data[colname].apply(lambda x : replacemap[x] if x != None else x )\n",
    "\n",
    "    om1 = add_data[add_data['Target'] == 1][colname].value_counts().to_frame()\n",
    "    om2 = add_data[add_data['Target'] == 2][colname].value_counts().to_frame()\n",
    "    om3 = add_data[add_data['Target'] == 3][colname].value_counts().to_frame()\n",
    "    om4 = add_data[add_data['Target'] == 4][colname].value_counts().to_frame()\n",
    "\n",
    "    trace1 = go.Bar(y=om1[colname], x=om1.index, name=\"Extereme\", marker=dict(color='red', opacity=0.9))\n",
    "    trace2 = go.Bar(y=om2[colname], x=om2.index, name=\"Moderate\", marker=dict(color='red', opacity=0.5))\n",
    "    trace3 = go.Bar(y=om3[colname], x=om3.index, name=\"Vulnerable\", marker=dict(color='orange', opacity=0.9))\n",
    "    trace4 = go.Bar(y=om4[colname], x=om4.index, name=\"NonVulnerable\", marker=dict(color='orange', opacity=0.5))\n",
    "\n",
    "    data = [trace1, trace2, trace3, trace4]\n",
    "    layout = dict(title=title, legend=dict(y=1.1, orientation=\"h\"), barmode=\"stack\", margin=dict(l=50), height=400)\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    if plotme:\n",
    "        iplot(fig)\n",
    "        \n",
    "flr = {\"instlevel1\": \"No Education\", \"instlevel2\": \"Incomplete Primary\", \"instlevel3\": \"Complete Primary\", \n",
    "       \"instlevel4\": \"Incomplete Sc.\", \"instlevel5\": \"Complete Sc.\", \"instlevel6\": \"Incomplete Tech Sc.\",\n",
    "       \"instlevel7\": \"Complete Tech Sc.\", \"instlevel8\": \"Undergraduation\", \"instlevel9\": \"Postgraduation\"}\n",
    "combine2(\"instl\", \"education_details\", \"Education Details of Family Members\", flr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdf9f070828305f5b0d0090a6cc5ec7b389324ba",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If individual is over 19 or younger than 7 and missing years behind, set it to 0\n",
    "add_data.loc[((add_data['age'] > 19) | (add_data['age'] < 7)) & (add_data['rez_esc'].isnull()), 'rez_esc'] = 0\n",
    "\n",
    "# Add a flag for those between 7 and 19 with a missing value\n",
    "add_data['rez_esc-missing'] = add_data['rez_esc'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09a138121c1f335f052f65f629f5ca08127e5654",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_data.loc[add_data['rez_esc'] > 5, 'rez_esc'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dda66e595fabb641f787b1e9df12d2acca00ed2e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = add_data[['rez_esc', 'Target']].head(5)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8930e606c21f9f881df35dd19cacf8a6964dd969",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_categoricals(x, y, data, annotate = True):\n",
    "    \"\"\"Plot counts of two categoricals.\n",
    "    Size is raw count for each grouping.\n",
    "    Percentages are for a given value of y.\"\"\"\n",
    "    \n",
    "    # Raw counts \n",
    "    raw_counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = False))\n",
    "    raw_counts = raw_counts.rename(columns = {x: 'raw_count'})\n",
    "    \n",
    "    # Calculate counts for each group of x and y\n",
    "    counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = True))\n",
    "    \n",
    "    # Rename the column and reset the index\n",
    "    counts = counts.rename(columns = {x: 'normalized_count'}).reset_index()\n",
    "    counts['percent'] = 100 * counts['normalized_count']\n",
    "    \n",
    "    # Add the raw count\n",
    "    counts['raw_count'] = list(raw_counts['raw_count'])\n",
    "    \n",
    "    plt.figure(figsize = (14, 10))\n",
    "    # Scatter plot sized by percent\n",
    "    plt.scatter(counts[x], counts[y], edgecolor = 'k', color = 'lightgreen',\n",
    "                s = 100 * np.sqrt(counts['raw_count']), marker = 'o',\n",
    "                alpha = 0.6, linewidth = 1.5)\n",
    "    \n",
    "    if annotate:\n",
    "        # Annotate the plot with text\n",
    "        for i, row in counts.iterrows():\n",
    "            # Put text with appropriate offsets\n",
    "            plt.annotate(xy = (row[x] - (1 / counts[x].nunique()), \n",
    "                               row[y] - (0.15 / counts[y].nunique())),\n",
    "                         color = 'navy',\n",
    "                         s = f\"{round(row['percent'], 1)}%\")\n",
    "        \n",
    "    # Set tick marks\n",
    "    plt.yticks(counts[y].unique())\n",
    "    plt.xticks(counts[x].unique())\n",
    "    \n",
    "    # Transform min and max to evenly space in square root domain\n",
    "    sqr_min = int(np.sqrt(raw_counts['raw_count'].min()))\n",
    "    sqr_max = int(np.sqrt(raw_counts['raw_count'].max()))\n",
    "    \n",
    "    # 5 sizes for legend\n",
    "    msizes = list(range(sqr_min, sqr_max,\n",
    "                        int(( sqr_max - sqr_min) / 5)))\n",
    "    markers = []\n",
    "    \n",
    "    # Markers for legend\n",
    "    for size in msizes:\n",
    "        markers.append(plt.scatter([], [], s = 100 * size, \n",
    "                                   label = f'{int(round(np.square(size) / 100) * 100)}', \n",
    "                                   color = 'lightgreen',\n",
    "                                   alpha = 0.6, edgecolor = 'k', linewidth = 1.5))\n",
    "        \n",
    "    # Legend and formatting\n",
    "    plt.legend(handles = markers, title = 'Counts',\n",
    "               labelspacing = 3, handletextpad = 2,\n",
    "               fontsize = 16,\n",
    "               loc = (1.10, 0.19))\n",
    "    \n",
    "    plt.annotate(f'* Size represents raw count while % is for a given y value.',\n",
    "                 xy = (0, 1), xycoords = 'figure points', size = 10)\n",
    "    \n",
    "    # Adjust axes limits\n",
    "    plt.xlim((counts[x].min() - (6 / counts[x].nunique()), \n",
    "              counts[x].max() + (6 / counts[x].nunique())))\n",
    "    plt.ylim((counts[y].min() - (4 / counts[y].nunique()), \n",
    "              counts[y].max() + (4 / counts[y].nunique())))\n",
    "    plt.grid(None)\n",
    "    plt.xlabel(f\"{x}\"); plt.ylabel(f\"{y}\"); plt.title(f\"{y} vs {x}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b04cb99b0b662092cfd91af1b482bb6e86363f76",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_categoricals('rez_esc', 'Target', add_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d88ea4316281a7997fbae7845fed524e2ab3f1b6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_categoricals('escolari', 'Target', add_data, annotate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "16c2887f01c17c592489b44261d8713293549a2d"
   },
   "source": [
    "Imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71c82456368d18940766e8f21bf90f28e410b78e"
   },
   "source": [
    "Distribution of target for the case where either of these values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6323c725e71128d5b7e01030f5d1e23983ec904c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heads = add_data[(add_data['rez_esc-missing'] == 1)].copy()\n",
    "target = heads['Target'].value_counts().to_frame()\n",
    "print(target)\n",
    " #target = heads_target.value_counts().to_frame()\n",
    "levels = [\"4.0\", \"3.0\", \"2.0\", \"1.0\"]\n",
    "trace = go.Bar(y=target['Target'], x=levels, marker=dict(color='orange', opacity=0.6))\n",
    "layout = dict(title=\"Target Value Counts\", margin=dict(l=200), width=800, height=500)\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "574e8746be88aaaca23e739ec1b48aaf49b938af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heads = add_data[(add_data['v2a1-missing'] == 1)].copy()\n",
    "target = heads['Target'].value_counts().to_frame()\n",
    "print(target)\n",
    " #target = heads_target.value_counts().to_frame()\n",
    "levels = [\"4.0\", \"3.0\", \"2.0\", \"1.0\"]\n",
    "trace = go.Bar(y=target['Target'], x=levels, marker=dict(color='orange', opacity=0.6))\n",
    "layout = dict(title=\"Target Value Counts\", margin=dict(l=200), width=800, height=500)\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2123b7a75b1cbee18d2de931fc4d8c918ad2ff2a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Education Details, Status and Members\n",
    "def combine2(starter, colname, title, replacemap, plotme = True):\n",
    "    mats = [c for c in add_data.columns if c.startswith(starter)]\n",
    "    add_data[colname] = add_data.apply(lambda row : find_prominent(row, mats), axis=1)\n",
    "    add_data[colname] = add_data[colname].apply(lambda x : replacemap[x] if x != None else x )\n",
    "\n",
    "    om1 = add_data[add_data['Target'] == 1][colname].value_counts().to_frame()\n",
    "    om2 = add_data[add_data['Target'] == 2][colname].value_counts().to_frame()\n",
    "    om3 = add_data[add_data['Target'] == 3][colname].value_counts().to_frame()\n",
    "    om4 = add_data[add_data['Target'] == 4][colname].value_counts().to_frame()\n",
    "\n",
    "    trace1 = go.Bar(y=om1[colname], x=om1.index, name=\"Extreme\", marker=dict(color='red', opacity=0.9))\n",
    "    trace2 = go.Bar(y=om2[colname], x=om2.index, name=\"Moderate\", marker=dict(color='red', opacity=0.5))\n",
    "    trace3 = go.Bar(y=om3[colname], x=om3.index, name=\"Vulnerable\", marker=dict(color='orange', opacity=0.9))\n",
    "    trace4 = go.Bar(y=om4[colname], x=om4.index, name=\"NonVulnerable\", marker=dict(color='orange', opacity=0.5))\n",
    "\n",
    "    data = [trace1, trace2, trace3, trace4]\n",
    "    layout = dict(title=title, legend=dict(y=1.1, orientation=\"h\"), barmode=\"stack\", margin=dict(l=50), height=400)\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    if plotme:\n",
    "        iplot(fig)\n",
    "\n",
    "\n",
    "flr = {\"instlevel1\": \"No Education\", \"instlevel2\": \"Incomplete Primary\", \"instlevel3\": \"Complete Primary\", \n",
    "       \"instlevel4\": \"Incomplete Sc.\", \"instlevel5\": \"Complete Sc.\", \"instlevel6\": \"Incomplete Tech Sc.\",\n",
    "       \"instlevel7\": \"Complete Tech Sc.\", \"instlevel8\": \"Undergraduation\", \"instlevel9\": \"Postgraduation\"}\n",
    "combine2(\"instl\", \"education_details\", \"Education Details of Family Members\", flr)  \n",
    "\n",
    "flr = {\"estadocivil1\": \"< 10 years\", \"estadocivil2\": \"Free / Coupled union\", \"estadocivil3\": \"Married\", \n",
    "       \"estadocivil4\": \"Divorced\", \"estadocivil5\": \"Separated\", \"estadocivil6\": \"Widow\",\n",
    "       \"estadocivil7\": \"Single\"}\n",
    "combine2(\"estado\", \"status_members\", \"Status of Family Members\", flr)  \n",
    "\n",
    "flr = {\"parentesco1\": \"Household Head\", \"parentesco2\": \"Spouse/Partner\", \"parentesco3\": \"Son/Daughter\", \n",
    "       \"parentesco4\": \"Stepson/Daughter\", \"parentesco5\" : \"Son/Daughter in Law\" , \"parentesco6\": \"Grandson/Daughter\", \n",
    "       \"parentesco7\": \"Mother/Father\", \"parentesco8\": \"Mother/Father in Law\", \"parentesco9\" : \"Brother/Sister\" , \n",
    "       \"parentesco10\" : \"Brother/Sister in law\", \"parentesco11\" : \"Other Family Member\", \"parentesco12\" : \"Other Non Family Member\"}\n",
    "combine2(\"parentesc\", \"family_members\", \"Family Members in the Households\", flr)  \n",
    "\n",
    "flr = {\"lugar1\": \"Central\", \"lugar2\": \"Chorotega\", \"lugar3\": \"PacÃƒÂ­fico central\", \n",
    "       \"lugar4\": \"Brunca\", \"lugar5\": \"Huetar AtlÃƒÂ¡ntica\", \"lugar6\": \"Huetar Norte\"}\n",
    "combine2(\"lugar\", \"region\", \"Region of the Households\", flr, plotme=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d6001463a1142ed3d5967496e7ecc0a35fcb708",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gender and Age Distributions\n",
    "\n",
    "def agbr(col):\n",
    "    temp1 = train_data[add_data['Target'] == 1][col].value_counts()\n",
    "    trace1 = go.Bar(x=temp1.index, y=temp1.values, marker=dict(color=\"red\", opacity=0.89), name=\"Extreme\")\n",
    "\n",
    "    temp2 = train_data[add_data['Target'] == 2][col].value_counts()\n",
    "    trace2 = go.Bar(x=temp2.index, y=temp2.values, marker=dict(color=\"orange\", opacity=0.79), name=\"Moderate\")\n",
    "\n",
    "    temp3 = train_data[add_data['Target'] == 3][col].value_counts()\n",
    "    trace3 = go.Bar(x=temp3.index, y=temp3.values, marker=dict(color=\"purple\", opacity=0.89), name=\"Vulnerable\")\n",
    "\n",
    "    temp4 = train_data[add_data['Target'] == 4][col].value_counts()\n",
    "    trace4 = go.Bar(x=temp4.index, y=temp4.values, marker=dict(color=\"green\", opacity=0.79), name=\"NonVulnerable\")\n",
    "    \n",
    "    return [trace1, trace2, trace3, trace4]\n",
    "    layout = dict(height=400)\n",
    "    fig = go.Figure(data=[trace1, trace2, trace3, trace4], layout=layout)\n",
    "    iplot(fig)\n",
    "\n",
    "titles = [\"Total Persons\", \"< 12 Yrs\", \">= 12 Yrs\", \"Total Males\", \"Males < 12 Yrs\", \"Males >= 12 Yrs\", \n",
    "         \"Total Females\", \"Females < 12 Yrs\", \"Females >= 12 Yrs\"]\n",
    "fig = tools.make_subplots(rows=3, cols=3, print_grid=False, subplot_titles=titles)\n",
    "\n",
    "res = agbr('r4t1')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 1)\n",
    "res = agbr('r4t2')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 2)\n",
    "res = agbr('r4t3')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 3)\n",
    "\n",
    "res = agbr('r4h1')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 2, 1)\n",
    "res = agbr('r4h2')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 2, 2)\n",
    "res = agbr('r4h3')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 2, 3)\n",
    "\n",
    "res = agbr('r4m1')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 3, 1)\n",
    "res = agbr('r4m2')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 3, 2)\n",
    "res = agbr('r4m3')\n",
    "for x in res:\n",
    "    fig.append_trace(x, 3, 3)\n",
    "\n",
    "    \n",
    "fig['layout'].update(height=750, showlegend=False, title=\"Gender and Age Distributions\")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e672eaf062cb3a02de27b92745e096ad5fbec851",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age groups among the household\n",
    "titles = [\"Children\", \"Adults\", \"65+ Old\"]\n",
    "fig = tools.make_subplots(rows=1, cols=3, print_grid=False, subplot_titles=titles)\n",
    "\n",
    "res = agbr(\"hogar_nin\")\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 1)\n",
    "res = agbr(\"hogar_adul\")\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 2)\n",
    "res = agbr(\"hogar_mayor\")\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 3)\n",
    "\n",
    "fig['layout'].update(height=350, title=\"People Distribution in Households\", barmode=\"stack\", showlegend=False)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "498b923b14765db79c491ac77a62202a15214f8c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age groups among the households\n",
    "titles = [\"Children\", \"Adults\", \"65+ Old\"]\n",
    "fig = tools.make_subplots(rows=1, cols=3, print_grid=False, subplot_titles=titles)\n",
    "\n",
    "res = agbr(\"hogar_nin\")\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 1)\n",
    "res = agbr(\"hogar_adul\")\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 2)\n",
    "res = agbr(\"hogar_mayor\")\n",
    "for x in res:\n",
    "    fig.append_trace(x, 1, 3)\n",
    "\n",
    "fig['layout'].update(height=350, title=\"People Distribution in Households\", barmode=\"stack\", showlegend=False)\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2956c52b3d5d232071fe7ab7f7b4a2b18b679e75",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Household size\n",
    "tm = agbr('tamhog')\n",
    "layout = dict(title=\"Household People Size\", margin=dict(l=100), height=400, legend=dict(orientation=\"h\", y=1))\n",
    "fig = go.Figure(data=tm, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f4c97d2f16bb04da889ae3f06efe1af353f18f0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Poverty Levels with respect to Monthly Rent and Age of the House\n",
    "trace0 = go.Scatter(x=train_data['v2a1'], y=train_data['age'], name=\"Extereme\", \n",
    "                    mode='markers', marker=dict(color=train_data['Target'], opacity=1, size=16 - train_data['Target']**2))\n",
    "layout = go.Layout(xaxis=dict(title=\"Monthly Rent of the house\", range=(0,400000)), yaxis=dict(title=\"Age of the House\"))\n",
    "fig = go.Figure(data =[trace0], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90f5111186cc2681ccf7640cf0a84fed92b0f440",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Area/Location Details\n",
    "# Area Type with Respect to Poverty Levels\n",
    "train_data['area_type'] = train_data['area1'].apply(lambda x: \"urbal\" if x==1 else \"rural\")\n",
    "\n",
    "cols = ['area_type', 'Target']\n",
    "colmap = sns.light_palette(\"yellow\", as_cmap=True)\n",
    "pd.crosstab(add_data[cols[1]], train_data[cols[0]]).style.background_gradient(cmap = colmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8669cb878a2b577848b61f84bb92f9cf950d49ef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Region with respect to Poverty Levels\n",
    "\n",
    "cols = ['region', 'Target']\n",
    "colmap = sns.light_palette(\"orange\", as_cmap=True)\n",
    "pd.crosstab(add_data[cols[0]], add_data[cols[1]]).style.background_gradient(cmap = colmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ce4921a5bb52de44e5d071dcdd01df115b897c3"
   },
   "source": [
    "Feature Engineering\n",
    "1. Individual Variable: Characteristics of each individual rather than the household\n",
    "    *  Boolean: 0 or 1\n",
    "    * Ordered Discrete: Integers with an ordering\n",
    "2. Household Variables: \n",
    "    * Boolean: 0 or 1\n",
    "    * Ordered Discrete: Integers with an ordering\n",
    "    * Continuous numeric\n",
    "3. Squared Variables\n",
    "    * Deriverd from squaring variable in the data\n",
    "4. Id Variables\n",
    "    * Identifies the data and should not be used as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7035a92c93cb6394bcced19fca7b7f5f0dff8c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_var = ['Id', 'idhogar', 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e872a2ebaa781d2d6303066cf983ca03786fee3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_bool = ['v18q', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', \n",
    "            'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "            'parentesco1', 'parentesco2',  'parentesco3', 'parentesco4', 'parentesco5', \n",
    "            'parentesco6', 'parentesco7', 'parentesco8',  'parentesco9', 'parentesco10', \n",
    "            'parentesco11', 'parentesco12', 'instlevel1', 'instlevel2', 'instlevel3', \n",
    "            'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', \n",
    "            'instlevel9', 'mobilephone', 'rez_esc-missing']\n",
    "\n",
    "ind_ordered = ['rez_esc', 'escolari', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14b8a297e148f21592b3833d92ec14794ad86620",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_bool = ['hacdor', 'hacapo', 'v14a', 'refrig', 'paredblolad', 'paredzocalo', \n",
    "           'paredpreb','pisocemento', 'pareddes', 'paredmad',\n",
    "           'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisoother', \n",
    "           'pisonatur', 'pisonotiene', 'pisomadera',\n",
    "           'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', \n",
    "           'abastaguadentro', 'abastaguafuera', 'abastaguano',\n",
    "            'public', 'planpri', 'noelec', 'coopele', 'sanitario1', \n",
    "           'sanitario2', 'sanitario3', 'sanitario5',   'sanitario6',\n",
    "           'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', \n",
    "           'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', \n",
    "           'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3',\n",
    "           'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', \n",
    "           'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', \n",
    "           'computer', 'television', 'lugar1', 'lugar2', 'lugar3',\n",
    "           'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'v2a1-missing']\n",
    "\n",
    "hh_ordered = [ 'rooms', 'r4h1', 'r4h2', 'r4h3', 'r4m1','r4m2','r4m3', 'r4t1',  'r4t2', \n",
    "              'r4t3', 'v18q1', 'tamhog','tamviv','hhsize','hogar_nin',\n",
    "              'hogar_adul','hogar_mayor','hogar_total',  'bedrooms', 'qmobilephone']\n",
    "\n",
    "hh_cont = ['v2a1', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'overcrowding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e437e3f8fe92b4eb821f755962d17d1c3f8d2545",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqr_ = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', \n",
    "        'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8e70777b6554409eb31f5277a4527da731b1d84",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ind_bool + ind_ordered + ind_bool + hh_bool + hh_ordered + hh_cont + sqr_\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print('There are no repeats: ', np.all(np.array(list(Counter(x).values())) == 1))\n",
    "print('We covered every variable: ', len(x) == add_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "deecb8f06646ac81768d5f5c31b5b86d5dd7763b"
   },
   "source": [
    "Squared Variables\n",
    "- Remove squared variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3aa0759c8d982fa0f01121dea600c40e5499ee4b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot('age', 'SQBage', data = add_data, fit_reg=False);\n",
    "plt.title('Squared Age versus Age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81f3609f20d49ccd807631022992df41467d285d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating trace1\n",
    "trace1 = go.Scatter(\n",
    "                    x = add_data['age'],\n",
    "                    y = add_data['SQBage'],\n",
    "                    mode = \"markers\")\n",
    "\n",
    "data = [trace1]\n",
    "layout = dict(title = 'Squared Age versus Age',\n",
    "              xaxis= dict(title= 'World Rank',ticklen= 5,zeroline= False)\n",
    "             )\n",
    "fig = dict(data = data, layout = layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8de001f23f20fab8f1fb88351b7e2d87f35c852",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove squared variables\n",
    "add_data = add_data.drop(columns = sqr_)\n",
    "add_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "781ae6c287b3c55615fe2bcb6d454cdbb579e6b6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(add_data.columns)\n",
    "from collections import Counter\n",
    "\n",
    "print('There are no repeats: ', np.all(np.array(list(Counter(x).values())) == 1))\n",
    "print('We covered every variable: ', len(x) == add_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c609c1d461d88193ca14898a83a58bbaf095362f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
